{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4438a07",
   "metadata": {},
   "source": [
    "## 파이콘 벡터 DB에 저장 및 검색이 가능하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff98dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 패키지/라이브러리 설치\n",
    "# %pip install -qU docx2txt langchain_community langchain-text-splitters langchain_chroma\n",
    "# %pip install langchain-pinecone\n",
    "# %pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baab1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2\\miniconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# 1. 문서 내용 읽고 분할 \n",
    "loader = Docx2txtLoader('law_2.docx') # --> 인스턴스 생성\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter( # --> 분할 설정\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 2. 임베딩 -> 백터 데이터베이스에 저장 \n",
    "## 2.1 환경변수 읽어오기\n",
    "load_dotenv()\n",
    "\n",
    "## 2.2 임베딩 모델 지정\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model='text-embedding-3-large'\n",
    ")\n",
    "\n",
    "## 2.3 Pinecone: server\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1393b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 벡터 스토어에 저장(한번만 실행)\n",
    "database = PineconeVectorStore.from_documents(\n",
    "    index_name='law-index-2',\n",
    "    embedding=embedding,\n",
    "    documents=document_list,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba53ebab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'전세사기 피해주택 임대인의 국세는 다음과 같은 계산식을 사용하여 산정합니다:\\n\\n1. 상속세, 증여세 및 종합부동산세의 경우:\\n   A × (B / C)\\n\\n   - A: 전세사기피해주택의 임대인이 체납한 고지 또는 신고 건별 국세 금액\\n   - B: 전세사기피해주택의 가격\\n   - C: 전세사기피해주택의 임대인이 보유한 모든 주택의 가격 합계액\\n\\n관련 법률 조항: 전세사기피해자 지원 및 주거안정에 관한 특별법 시행령 제3조제1항제1호가목.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2.5 벡터 스토어에서 읽어오기\n",
    "database = PineconeVectorStore(\n",
    "    index_name='law-index-2',\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "# 3. 질문이 있으면, 벡터 데이터베이스에서 유사도 검색  #############\n",
    "## 3.1 사용자 질문\n",
    "query = '전세사기 피해주택 임대인의 국세는 어떻게 계산하나요? 정확한 수식을 알려주세요'\n",
    "\n",
    "## 3.2 벡터 데이터베이스에서 유사도 검색\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "# 4. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달 ###########\n",
    "## 4.1 프롬프트 작성\n",
    "prompt = '''\n",
    "[identity]\n",
    "- 당신은 전세사기 피해 법률 전문가입니다.\n",
    "- [context]를 참고하여 사용자의 질문에 답변해주세요.\n",
    "- 답변시 관련 법률 조항을 같이 출력하세요.\n",
    "- 전세사기피해 법률 이외의 질문에는 '답변을 할 수 없습니다.'로 답하세요.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "'''\n",
    "\n",
    "## 4.2 프롬프트 변수에 값 설정(format 함수)\n",
    "formatted_prompt = prompt.format(retrieved_docs=retrieved_docs, query=query)\n",
    "\n",
    "## 4.3 LLM 모델 생성(ChatOpenAI 인스턴스 생성)\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "## 4.4 LLM 모델에 질문과 검색된 문서를 보냄\n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
