{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f0b076",
   "metadata": {},
   "source": [
    "# [ë¬¸ì œ]\n",
    "- law_2.docx íŒŒì¼ì„ ì½ê³ , Chromaì— ì €ìž¥\n",
    "- LLM ì§ˆë¬¸ -> ë‹µë³€\n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ì— ê´€í•œ ë²•ë¥  ì§ˆë¬¸ë§Œ ë°›ê¸°\n",
    "- ì´ ì™¸ì˜ ì§ˆë¬¸ì€ 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "database = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    collection_name='chroma-law-2',\n",
    "    persist_directory='./chroma',\n",
    "    embedding=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ca445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database = Chroma(\n",
    "    collection_name='chroma-law-2',\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "query = 'ì˜¤ëŠ˜ì˜ ì ì‹¬ ë©”ë‰´ëŠ”?'\n",
    "\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "prompt = '''\n",
    "[identity]\n",
    "- ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.\n",
    "- [context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ì´ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "'''\n",
    "\n",
    "context = 'ðŸ˜Š\\n'.join([doc.page_content for doc in retrieved_docs]) # -> list ë‚´ for ë¬¸\n",
    "\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=context, \n",
    "    query=query)\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "print(ai_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
